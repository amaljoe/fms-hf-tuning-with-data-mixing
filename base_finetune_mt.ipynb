{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T18:54:59.664563Z",
     "start_time": "2025-03-08T18:54:54.021013Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from pandas import DataFrame\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "model_path=\"base_models/granite-3.2-2b-instruct\"\n",
    "device= \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f699a9e81d7452ba364f6e2c1367a63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:54:51.235304Z",
     "start_time": "2025-03-08T18:54:51.067274Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer(\"input\", \"input\", \"input\", \"inputs\", return_tensors=\"pt\")",
   "id": "fdec98e789dbb275",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tokenizer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minputs\u001B[39m\u001B[38;5;124m\"\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "67a8c0b1b01bb92d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:39:16.657750Z",
     "start_time": "2025-03-09T11:39:15.375541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "with open(\"data/coco.ml.txt\") as f:\n",
    "    ml = f.readlines()\n",
    "\n",
    "with open(\"data/coco.en.txt\") as f:\n",
    "    eng = f.readlines()\n",
    "\n",
    "def get_dataset(ml, eng):\n",
    "    ml = [sen.strip() for sen in ml]\n",
    "    eng = [sen.strip() for sen in eng]\n",
    "    return [{\"ml\": ml, \"eng\": eng, \"content\": f'Translate to english:<|end_of_text|>{ml}<|end_of_text|>{eng}<|end_of_text|>'} for ml, eng in zip(ml, eng)]\n",
    "\n",
    "dataset = get_dataset(ml, eng)\n",
    "n = len(dataset)\n",
    "train_dataset = Dataset.from_list(dataset[:n // 10 * 8])\n",
    "valid_dataset = Dataset.from_list(dataset[n // 10 * 8:n])\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"validation\": valid_dataset})\n",
    "dataset"
   ],
   "id": "f508b0757560a4d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ml', 'eng', 'content'],\n",
       "        num_rows: 289464\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ml', 'eng', 'content'],\n",
       "        num_rows: 72368\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:55:03.271396Z",
     "start_time": "2025-03-08T18:55:03.189739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "args = TrainingArguments(\"ml_to_en\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"content\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].clone()\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ],
   "id": "30d28654e4927ad4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6017c7229654c939019216cf9d647ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70c1497c44e9416a98bbb5b3ea476c65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ml', 'eng', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ml', 'eng', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:46:15.391955Z",
     "start_time": "2025-03-08T19:46:15.385993Z"
    }
   },
   "cell_type": "code",
   "source": "len(tokenized_datasets['train'][0]['input_ids'])",
   "id": "28dcdcdbd89d4a6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:55:08.596151Z",
     "start_time": "2025-03-08T18:55:04.663706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "3f67fafc6fe2679d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:55:15.051154Z",
     "start_time": "2025-03-08T18:55:10.916566Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.predict(tokenized_datasets['validation'])[0]",
   "id": "31c0898856dc504",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='None' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      None\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:01]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -5.53125   , -15.375     , -15.375     , ...,  -6.40625   ,\n",
       "          -5.34375   ,  -6.75      ],\n",
       "        [  5.3125    ,  -3.59375   ,  -3.59375   , ...,  -0.39453125,\n",
       "          -0.2578125 ,  -0.6953125 ],\n",
       "        [  9.125     ,  -5.15625   ,  -5.15625   , ...,   0.16210938,\n",
       "           0.87890625,  -0.90234375],\n",
       "        ...,\n",
       "        [ 18.        ,  -4.6875    ,  -4.6875    , ...,  -0.08984375,\n",
       "           0.63671875,  -0.39453125],\n",
       "        [ 16.875     ,  -5.6875    ,  -5.6875    , ...,  -0.54296875,\n",
       "          -0.05981445,  -0.875     ],\n",
       "        [ 16.375     ,  -4.8125    ,  -4.8125    , ...,  -0.37890625,\n",
       "          -0.03112793,  -0.60546875]],\n",
       "\n",
       "       [[ -5.53125   , -15.375     , -15.375     , ...,  -6.40625   ,\n",
       "          -5.34375   ,  -6.75      ],\n",
       "        [  5.3125    ,  -3.59375   ,  -3.59375   , ...,  -0.39453125,\n",
       "          -0.2578125 ,  -0.6953125 ],\n",
       "        [  9.125     ,  -5.15625   ,  -5.15625   , ...,   0.16210938,\n",
       "           0.87890625,  -0.90234375],\n",
       "        ...,\n",
       "        [ 17.75      ,  -5.6875    ,  -5.6875    , ...,  -0.50390625,\n",
       "           0.18554688,  -0.96484375],\n",
       "        [ 17.375     ,  -5.34375   ,  -5.34375   , ...,  -0.44140625,\n",
       "           0.26171875,  -0.90234375],\n",
       "        [ 15.375     ,  -6.53125   ,  -6.53125   , ...,  -0.83203125,\n",
       "          -0.4609375 ,  -1.3515625 ]],\n",
       "\n",
       "       [[ -5.53125   , -15.375     , -15.375     , ...,  -6.40625   ,\n",
       "          -5.34375   ,  -6.75      ],\n",
       "        [  5.3125    ,  -3.59375   ,  -3.59375   , ...,  -0.39453125,\n",
       "          -0.2578125 ,  -0.6953125 ],\n",
       "        [  9.125     ,  -5.15625   ,  -5.15625   , ...,   0.16210938,\n",
       "           0.87890625,  -0.90234375],\n",
       "        ...,\n",
       "        [ 14.3125    ,  -5.59375   ,  -5.59375   , ...,  -1.1875    ,\n",
       "          -0.57421875,  -1.375     ],\n",
       "        [ 16.875     ,  -4.90625   ,  -4.90625   , ...,  -0.65234375,\n",
       "           0.07958984,  -0.91796875],\n",
       "        [ 15.25      ,  -4.46875   ,  -4.46875   , ...,  -0.34765625,\n",
       "           0.08154297,  -0.703125  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -5.53125   , -15.375     , -15.375     , ...,  -6.40625   ,\n",
       "          -5.34375   ,  -6.75      ],\n",
       "        [  5.3125    ,  -3.59375   ,  -3.59375   , ...,  -0.39453125,\n",
       "          -0.2578125 ,  -0.6953125 ],\n",
       "        [  9.125     ,  -5.15625   ,  -5.15625   , ...,   0.16210938,\n",
       "           0.87890625,  -0.90234375],\n",
       "        ...,\n",
       "        [ 16.625     ,  -4.625     ,  -4.625     , ...,  -0.24316406,\n",
       "           0.03149414,  -0.71875   ],\n",
       "        [ 16.        ,  -5.03125   ,  -5.03125   , ...,  -0.6171875 ,\n",
       "          -0.04541016,  -0.84375   ],\n",
       "        [ 16.875     ,  -4.625     ,  -4.625     , ...,  -0.20117188,\n",
       "           0.31835938,  -0.64453125]],\n",
       "\n",
       "       [[ -5.53125   , -15.375     , -15.375     , ...,  -6.40625   ,\n",
       "          -5.34375   ,  -6.75      ],\n",
       "        [  5.3125    ,  -3.59375   ,  -3.59375   , ...,  -0.39453125,\n",
       "          -0.2578125 ,  -0.6953125 ],\n",
       "        [  9.125     ,  -5.15625   ,  -5.15625   , ...,   0.16210938,\n",
       "           0.87890625,  -0.90234375],\n",
       "        ...,\n",
       "        [ 18.375     ,  -5.15625   ,  -5.15625   , ...,  -0.24121094,\n",
       "           0.36523438,  -0.4453125 ],\n",
       "        [ 15.3125    ,  -4.65625   ,  -4.65625   , ...,  -0.57421875,\n",
       "          -0.22460938,  -0.78125   ],\n",
       "        [ 16.75      ,  -4.46875   ,  -4.46875   , ...,  -0.41015625,\n",
       "           0.14746094,  -0.57421875]],\n",
       "\n",
       "       [[ -5.53125   , -15.375     , -15.375     , ...,  -6.40625   ,\n",
       "          -5.34375   ,  -6.75      ],\n",
       "        [  5.3125    ,  -3.59375   ,  -3.59375   , ...,  -0.39453125,\n",
       "          -0.2578125 ,  -0.6953125 ],\n",
       "        [  9.125     ,  -5.15625   ,  -5.15625   , ...,   0.16210938,\n",
       "           0.87890625,  -0.90234375],\n",
       "        ...,\n",
       "        [ 15.5       ,  -5.78125   ,  -5.78125   , ...,  -0.5625    ,\n",
       "          -0.5       ,  -0.87890625],\n",
       "        [ 14.625     ,  -5.71875   ,  -5.71875   , ...,  -0.96484375,\n",
       "          -0.86328125,  -1.21875   ],\n",
       "        [ 14.25      ,  -5.6875    ,  -5.6875    , ...,  -1.078125  ,\n",
       "          -1.0234375 ,  -1.2109375 ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:04:09.788317Z",
     "start_time": "2025-03-08T19:04:04.903020Z"
    }
   },
   "cell_type": "code",
   "source": "pred = trainer.predict(tokenized_datasets['validation'])",
   "id": "f778bc6ae0a8771c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:09:19.552454Z",
     "start_time": "2025-03-08T19:09:19.550270Z"
    }
   },
   "cell_type": "code",
   "source": "type(pred.predictions)",
   "id": "63402cfacf67c1b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:10:55.080395Z",
     "start_time": "2025-03-08T19:10:54.919530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import bleu_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = np.argmax(pred.predictions, axis=-1)\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    # labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    bleu = bleu_score.corpus_bleu(label_str, pred_str, smoothing_function=bleu_score.SmoothingFunction().method7)\n",
    "    return {\"bleu\": bleu}\n",
    "\n",
    "compute_metrics(pred)"
   ],
   "id": "727e015a906e3e6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 144) (20, 144)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.09299390537329787}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T00:09:33.445738Z",
     "start_time": "2025-03-09T00:09:31.375623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ml_test = 'എയർപോർട്ട് ടാർമാക്കിന്റെ മുകളിൽ ഇരിക്കുന്ന ഒരു വലിയ വെളുത്ത ജെറ്റ്'\n",
    "ip = tokenizer(f'Translate to english:<|end_of_text|>{ml_test}<|end_of_text|>', return_tensors=\"pt\").to(device)\n",
    "op = model.generate(**ip, max_length=200)\n",
    "tokenizer.decode(op[0])"
   ],
   "id": "9d91807006114098",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate to english:<|end_of_text|>എയർപോർട്ട് ടാർമാക്കിന്റെ മുകളിൽ ഇരിക്കുന്ന ഒരു വലിയ വെളുത്ത ജെറ്റ്<|end_of_text|>\\n\\nA large jet engine in the rear of the Eyroport Tramack.<|end_of_text|>'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T02:35:43.321077Z",
     "start_time": "2025-03-09T02:35:22.576257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path_ours = \"base_models/granite-3.2-2b-instruct\"\n",
    "\n",
    "model_ours = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path_ours,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer_ours = AutoTokenizer.from_pretrained(\n",
    "    model_path_ours,\n",
    ")"
   ],
   "id": "676724e8725b1d79",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "388d4eee87a54444936128050634781e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_test = 2\n",
    "\n",
    "ml_test = dataset['validation']['ml'][:num_test]\n",
    "eng_test = dataset['validation']['eng'][:num_test]\n",
    "\n",
    "ip_content = [f'Translate to english:<|end_of_text|>{test}<|end_of_text|>' for test in ml_test]\n",
    "ip = tokenizer_ours(ip_content, return_tensors=\"pt\", padding=True).to(device)\n",
    "ip_base = tokenizer(ip_content, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "ip_length = ip['input_ids'].shape[-1]\n",
    "\n",
    "op = model_ours.generate(**ip, max_length=200)\n",
    "op_base = model.generate(**ip_base, max_length=200)"
   ],
   "id": "5ccd9eae6ad2cc01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T02:51:26.612709Z",
     "start_time": "2025-03-09T02:51:26.610187Z"
    }
   },
   "cell_type": "code",
   "source": ".shape",
   "id": "577d3b0a719c574e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T02:48:50.127207Z",
     "start_time": "2025-03-09T02:48:50.052972Z"
    }
   },
   "cell_type": "code",
   "source": "cop = op[:, ip['input_ids'].shape[-1]:]",
   "id": "35e113cdd3b2e340",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([16076,   372, 40230,    44,     0,  8747,   232,  8747,   116, 39770,\n",
       "          8747,   133,  8747,   126, 41125,  8747,   127,  8747,   125,  8747,\n",
       "           141,  8747,   126, 39770, 27251,   116, 13525,   238, 49057, 21185,\n",
       "         49057, 45556, 49057, 21185, 49057, 27251,   245,  8747,   127, 45556,\n",
       "         27251,   124,  8747,   141,  8747,   136, 21185,  8747,   126, 27251,\n",
       "           135, 21185,  8747,   117,  8747,   129,  8747,   116, 21185,  8747,\n",
       "           116, 39770, 49057, 21185,  8747,   128, 13525,   233, 27251,   253,\n",
       "         39770,  8747,   116, 21185,  8747,   127,  8747,   229,    32,     0,\n",
       "           203,    51,   343,  4325,   689,   409,  1295,   382,   432,   312,\n",
       "         28805,    30,   408,   837,    86,  5122,    32,     0],\n",
       "        device='mps:0'),\n",
       " tensor([16076,   372, 40230,    44,     0,  8747,   232,  8747,   116, 39770,\n",
       "          8747,   133,  8747,   126, 41125,  8747,   127,  8747,   125,  8747,\n",
       "           141,  8747,   126, 39770, 27251,   116, 13525,   238, 49057, 21185,\n",
       "         49057, 45556, 49057, 21185, 49057, 27251,   245,  8747,   127, 45556,\n",
       "         27251,   124,  8747,   141,  8747,   136, 21185,  8747,   126, 27251,\n",
       "           135, 21185,  8747,   117,  8747,   129,  8747,   116, 21185,  8747,\n",
       "           116, 39770, 49057, 21185,  8747,   128, 13525,   233, 27251,   253,\n",
       "         39770,  8747,   116, 21185,  8747,   127,  8747,   229,    32,     0],\n",
       "        device='mps:0'))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T02:52:42.040206Z",
     "start_time": "2025-03-09T02:52:42.026100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cop = op[:, ip['input_ids'].shape[-1] + 1:]\n",
    "cop_base = op_base[:, ip['input_ids'].shape[-1] + 1:]\n",
    "\n",
    "# get only generated part\n",
    "op_str = tokenizer_ours.batch_decode(cop, skip_special_tokens=True)\n",
    "op_base_str = tokenizer.batch_decode(cop_base, skip_special_tokens=True)\n",
    "\n",
    "bleu = [bleu_score.sentence_bleu([eng], op, smoothing_function=bleu_score.SmoothingFunction().method7) * 100 for eng, op in zip(eng_test, op_str)]\n",
    "bleu_base = [bleu_score.sentence_bleu([eng], op, smoothing_function=bleu_score.SmoothingFunction().method7) * 100 for eng, op in zip(eng_test, op_base_str)]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"ml\": ml_test, \"eng\": eng_test, \"op\": op_str, \"op_base\": op_base_str, \"bleu\": bleu, \"bleu_base\": bleu_base})\n",
    "df.to_csv(\"base_finetune_mt.csv\")"
   ],
   "id": "e7bf16f9fb817858",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                      ml  \\\n",
       "0  ഒരു നഗരത്തിലെ പാർക്കിംഗിനായി ഒരു കുട്ടി പണം നൽകുന്നു.   \n",
       "1   അതിശയകരമായി തോന്നുന്ന ഒരു ബാഹ്യ സ്ഥലത്തിന്റെ ചിത്രം.   \n",
       "\n",
       "                                                  eng  \\\n",
       "0                 A child pays for parking in a city.   \n",
       "1  Picture of an exterior place that looks wonderful.   \n",
       "\n",
       "                                                  op  \\\n",
       "0  A girl in a city earns money by selling her body.   \n",
       "1   A dramatic depiction of a quiet, secluded space.   \n",
       "\n",
       "                                             op_base       bleu  bleu_base  \n",
       "0  A girl in a city earns money by selling her body.  38.737708  38.737708  \n",
       "1   A dramatic depiction of a quiet, secluded space.  27.195199  27.195199  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml</th>\n",
       "      <th>eng</th>\n",
       "      <th>op</th>\n",
       "      <th>op_base</th>\n",
       "      <th>bleu</th>\n",
       "      <th>bleu_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ഒരു നഗരത്തിലെ പാർക്കിംഗിനായി ഒരു കുട്ടി പണം നൽകുന്നു.</td>\n",
       "      <td>A child pays for parking in a city.</td>\n",
       "      <td>A girl in a city earns money by selling her body.</td>\n",
       "      <td>A girl in a city earns money by selling her body.</td>\n",
       "      <td>38.737708</td>\n",
       "      <td>38.737708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>അതിശയകരമായി തോന്നുന്ന ഒരു ബാഹ്യ സ്ഥലത്തിന്റെ ചിത്രം.</td>\n",
       "      <td>Picture of an exterior place that looks wonderful.</td>\n",
       "      <td>A dramatic depiction of a quiet, secluded space.</td>\n",
       "      <td>A dramatic depiction of a quiet, secluded space.</td>\n",
       "      <td>27.195199</td>\n",
       "      <td>27.195199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:39:25.931214Z",
     "start_time": "2025-03-09T11:39:21.056854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.DataFrame(dataset['train'])\n",
    "print(len(train_df))\n",
    "# deduplication\n",
    "train_df = train_df.drop_duplicates()\n",
    "print(len(train_df))"
   ],
   "id": "44f267d65b4c1ae1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289464\n",
      "270880\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:40:10.990127Z",
     "start_time": "2025-03-09T11:40:09.779709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_df = pd.DataFrame(dataset['validation'])\n",
    "print(len(val_df))\n",
    "# deduplication\n",
    "val_df = val_df.drop_duplicates()\n",
    "print(len(val_df))"
   ],
   "id": "c3aea223cb436c46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72368\n",
      "71043\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:41:15.265315Z",
     "start_time": "2025-03-09T11:41:09.175217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# combined\n",
    "train2_df = pd.DataFrame(dataset['train'])\n",
    "val2_df = pd.DataFrame(dataset['validation'])\n",
    "full_df = pd.concat([train2_df, val2_df])\n",
    "print(len(full_df))\n",
    "# deduplication\n",
    "full_df = full_df.drop_duplicates()\n",
    "print(len(full_df))"
   ],
   "id": "8cad85c9b2207614",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361832\n",
      "341149\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:42:37.574624Z",
     "start_time": "2025-03-09T11:42:37.571016Z"
    }
   },
   "cell_type": "code",
   "source": "361832 - 341149 - (289464 - 270880) - (72368 - 71043)",
   "id": "a3978bb5ebf279c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
