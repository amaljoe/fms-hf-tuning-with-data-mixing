{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T07:15:57.349801Z",
     "start_time": "2025-03-04T07:15:31.906443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "import torch\n",
    "\n",
    "model_path=\"ibm-granite/granite-3.2-2b-instruct\"\n",
    "device= \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path\n",
    ")\n",
    "\n",
    "model.save_pretrained(\"base_models/granite-3.2-2b-instruct\")"
   ],
   "id": "fad730d1f2c7246b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c9c7248fe8b44108e14a7c54a3efc17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:41:16.742866Z",
     "start_time": "2025-03-03T20:41:15.049161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv = [{\"role\": \"user\", \"content\":\"Translate to english: കണ്ണടയും തൊപ്പിയും ധരിച്ച ഒരാളുടെ ക്ലോസ് അപ്പ്\"}]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(conv, return_tensors=\"pt\", thinking=False, return_dict=True, add_generation_prompt=True).to(device)\n",
    "set_seed(42)\n",
    "output = model.generate(\n",
    "    **input_ids,\n",
    "    max_new_tokens=8192,\n",
    ")\n",
    "\n",
    "prediction = tokenizer.decode(output[0, input_ids[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "print(prediction)"
   ],
   "id": "123550f02640db5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person's closet filled with both canes and crutches.\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:01:57.213252Z",
     "start_time": "2025-03-03T20:01:56.841012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def preprocess_data(sources, destinations):\n",
    "    dataset = [[{\"role\": \"user\", \"content\": f\"Translate to english: {src}\"} , {\"role\": \"assistant\", \"content\": dest}] for src, dest in zip(sources, destinations)]\n",
    "    dataset = Dataset.from_dict({\"formatted_chat\": dataset})\n",
    "    return dataset.map(lambda x: {\"formatted_chat\": tokenizer.apply_chat_template(x, tokenize=False, add_generation_prompt=False)})\n",
    "\n",
    "def get_translation_loss(examples):\n",
    "    input_ids = tokenizer.apply_chat_template(examples, return_tensors=\"pt\", thinking=False, return_dict=True, add_generation_prompt=True).to(device)\n",
    "    print(input_ids)\n",
    "    \n",
    "\n",
    "with open(\"data/coco.ml.txt\", \"r\") as f:\n",
    "    src_data = f.readlines()\n",
    "\n",
    "with open(\"data/coco.en.txt\", \"r\") as f:\n",
    "    dest_data = f.readlines()\n",
    "\n",
    "data = preprocess_data(src_data[:10], dest_data[:10])\n",
    "data"
   ],
   "id": "1daf0deb54b5bc9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21629dc6713248e69a05efaa05d0f84d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UndefinedError",
     "evalue": "datasets.formatting.formatting.LazyRow object has no element 0",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUndefinedError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[62]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mdata/coco.en.txt\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m     17\u001B[39m     dest_data = f.readlines()\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m data = \u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m data\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[62]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mpreprocess_data\u001B[39m\u001B[34m(sources, destinations)\u001B[39m\n\u001B[32m      4\u001B[39m dataset = [[{\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTranslate to english: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msrc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m} , {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33massistant\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: dest}] \u001B[38;5;28;01mfor\u001B[39;00m src, dest \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sources, destinations)]\n\u001B[32m      5\u001B[39m dataset = Dataset.from_dict({\u001B[33m\"\u001B[39m\u001B[33mformatted_chat\u001B[39m\u001B[33m\"\u001B[39m: dataset})\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mformatted_chat\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply_chat_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenize\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:602\u001B[39m, in \u001B[36mtransmit_tasks.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    600\u001B[39m     \u001B[38;5;28mself\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mself\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    601\u001B[39m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m602\u001B[39m out: Union[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mDatasetDict\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    603\u001B[39m datasets: List[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mlist\u001B[39m(out.values()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[32m    604\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[32m    605\u001B[39m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:567\u001B[39m, in \u001B[36mtransmit_format.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    560\u001B[39m self_format = {\n\u001B[32m    561\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtype\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_type,\n\u001B[32m    562\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mformat_kwargs\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_kwargs,\n\u001B[32m    563\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_columns,\n\u001B[32m    564\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33moutput_all_columns\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._output_all_columns,\n\u001B[32m    565\u001B[39m }\n\u001B[32m    566\u001B[39m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m567\u001B[39m out: Union[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mDatasetDict\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    568\u001B[39m datasets: List[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mlist\u001B[39m(out.values()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[32m    569\u001B[39m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3167\u001B[39m, in \u001B[36mDataset.map\u001B[39m\u001B[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[39m\n\u001B[32m   3161\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   3162\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[32m   3163\u001B[39m         unit=\u001B[33m\"\u001B[39m\u001B[33m examples\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   3164\u001B[39m         total=pbar_total,\n\u001B[32m   3165\u001B[39m         desc=desc \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mMap\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   3166\u001B[39m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[32m-> \u001B[39m\u001B[32m3167\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mDataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mdataset_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3168\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3169\u001B[39m \u001B[43m                \u001B[49m\u001B[43mshards_done\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3528\u001B[39m, in \u001B[36mDataset._map_single\u001B[39m\u001B[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[39m\n\u001B[32m   3526\u001B[39m _time = time.time()\n\u001B[32m   3527\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, example \u001B[38;5;129;01min\u001B[39;00m shard_iterable:\n\u001B[32m-> \u001B[39m\u001B[32m3528\u001B[39m     example = \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3529\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m update_data:\n\u001B[32m   3530\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m i == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3427\u001B[39m, in \u001B[36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[39m\u001B[34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[39m\n\u001B[32m   3425\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[32m   3426\u001B[39m     additional_args += (rank,)\n\u001B[32m-> \u001B[39m\u001B[32m3427\u001B[39m processed_inputs = \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfn_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43madditional_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3428\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[32m   3429\u001B[39m     processed_inputs = {\n\u001B[32m   3430\u001B[39m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs.data.items() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs.keys_to_format\n\u001B[32m   3431\u001B[39m     }\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[62]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mpreprocess_data.<locals>.<lambda>\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m      4\u001B[39m dataset = [[{\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTranslate to english: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msrc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m} , {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33massistant\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: dest}] \u001B[38;5;28;01mfor\u001B[39;00m src, dest \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sources, destinations)]\n\u001B[32m      5\u001B[39m dataset = Dataset.from_dict({\u001B[33m\"\u001B[39m\u001B[33mformatted_chat\u001B[39m\u001B[33m\"\u001B[39m: dataset})\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m dataset.map(\u001B[38;5;28;01mlambda\u001B[39;00m x: {\u001B[33m\"\u001B[39m\u001B[33mformatted_chat\u001B[39m\u001B[33m\"\u001B[39m: \u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply_chat_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenize\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m})\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1867\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.apply_chat_template\u001B[39m\u001B[34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001B[39m\n\u001B[32m   1865\u001B[39m     all_generation_indices.append(generation_indices)\n\u001B[32m   1866\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1867\u001B[39m     rendered_chat = \u001B[43mcompiled_template\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1868\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1869\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtool_schemas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1870\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1871\u001B[39m \u001B[43m        \u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1872\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtemplate_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1873\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1874\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m continue_final_message:\n\u001B[32m   1875\u001B[39m     final_message = chat[-\u001B[32m1\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/jinja2/environment.py:1295\u001B[39m, in \u001B[36mTemplate.render\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.environment.concat(\u001B[38;5;28mself\u001B[39m.root_render_func(ctx))  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m   1294\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1295\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/jinja2/environment.py:942\u001B[39m, in \u001B[36mEnvironment.handle_exception\u001B[39m\u001B[34m(self, source)\u001B[39m\n\u001B[32m    937\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Exception handling helper.  This is used internally to either raise\u001B[39;00m\n\u001B[32m    938\u001B[39m \u001B[33;03mrewritten exceptions or return a rendered traceback for the template.\u001B[39;00m\n\u001B[32m    939\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    940\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdebug\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m rewrite_traceback_stack\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m rewrite_traceback_stack(source=source)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<template>:1\u001B[39m, in \u001B[36mtop-level template code\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/jinja2/sandbox.py:293\u001B[39m, in \u001B[36mSandboxedEnvironment.getitem\u001B[39m\u001B[34m(self, obj, argument)\u001B[39m\n\u001B[32m    291\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Subscribe an object from sandboxed code.\"\"\"\u001B[39;00m\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m[\u001B[49m\u001B[43margument\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mLookupError\u001B[39;00m):\n\u001B[32m    295\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(argument, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[31mUndefinedError\u001B[39m: datasets.formatting.formatting.LazyRow object has no element 0"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T06:59:00.851801Z",
     "start_time": "2025-03-04T06:59:00.364745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.2-2b-instruct\")"
   ],
   "id": "7c923be80083bd08",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T06:52:37.168458Z",
     "start_time": "2025-03-04T06:52:34.339736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count, n = 0, 10000\n",
    "for i in range(n):\n",
    "    sample = src_data[i]\n",
    "    count += tokenizer.decode(tokenizer.encode(sample)) == sample\n",
    "\n",
    "count / n"
   ],
   "id": "4e5b950333f95aff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T07:10:39.265706Z",
     "start_time": "2025-03-04T07:10:36.534148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset preparation\n",
    "\n",
    "# {\n",
    "#     \"messages\": [\n",
    "#         {\"role\": \"system\", \"content\": \"Translate the Malayalam text to English.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"മലയാളം ടെക്സ്റ്റ്\"},\n",
    "#         {\"role\": \"assistant\", \"content\": \"Malayalam text\"}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "n = len(src_data)\n",
    "dataset = []\n",
    "for mal, eng in zip(src_data[:n], dest_data[:n]):\n",
    "    sample = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Translate the Malayalam text to English.\"},\n",
    "            {\"role\": \"user\", \"content\": mal.strip()},\n",
    "            {\"role\": \"assistant\", \"content\": eng.strip()}\n",
    "        ]\n",
    "    }\n",
    "    dataset.append(sample)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"data/trans.jsonl\", \"w\") as f:\n",
    "    for sample in dataset:\n",
    "        f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")"
   ],
   "id": "496e1bfae4b06ddb",
   "outputs": [],
   "execution_count": 98
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
