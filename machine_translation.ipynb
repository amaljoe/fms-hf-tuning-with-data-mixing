{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:41:47.032071Z",
     "start_time": "2025-03-08T05:41:37.675476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "import torch\n",
    "\n",
    "model_path=\"base_models/granite-3.2-2b-instruct\"\n",
    "device= \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path\n",
    ")\n",
    "\n",
    "# model.save_pretrained(\"base_models/granite-3.2-2b-instruct\")\n",
    "# tokenizer.save_pretrained(\"base_models/granite-3.2-2b-instruct\")"
   ],
   "id": "fad730d1f2c7246b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f893d40bb8ab47d5b1649d9f288ced10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T13:44:56.715812Z",
     "start_time": "2025-03-04T13:44:56.700709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv = [{\"role\": \"user\", \"content\":\"Translate to english: കണ്ണടയും തൊപ്പിയും ധരിച്ച ഒരാളുടെ ക്ലോസ് അപ്പ്\"}]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(conv, return_tensors=\"pt\", thinking=False, return_dict=True, add_generation_prompt=True).to(device)\n",
    "set_seed(42)\n",
    "print(tokenizer.decode(input_ids['input_ids'][0]))\n",
    "\n",
    "import sys; sys.exit(0)\n",
    "\n",
    "output = model.generate(\n",
    "    **input_ids,\n",
    "    max_new_tokens=8192,\n",
    ")\n",
    "\n",
    "prediction = tokenizer.decode(output[0, input_ids[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "print(prediction)"
   ],
   "id": "123550f02640db5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_of_role|>system<|end_of_role|>Knowledge Cutoff Date: April 2024.\n",
      "Today's Date: March 04, 2025.\n",
      "You are Granite, developed by IBM. You are a helpful AI assistant.<|end_of_text|>\n",
      "<|start_of_role|>user<|end_of_role|>Translate to english: കണ്ണടയും തൊപ്പിയും ധരിച്ച ഒരാളുടെ ക്ലോസ് അപ്പ്<|end_of_text|>\n",
      "<|start_of_role|>assistant<|end_of_role|>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 0\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T16:33:58.362627Z",
     "start_time": "2025-03-04T16:33:57.897492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def preprocess_data(sources, destinations):\n",
    "    dataset = [[{\"role\": \"user\", \"content\": f\"Translate to english: {src}\"} , {\"role\": \"assistant\", \"content\": dest}] for src, dest in zip(sources, destinations)]\n",
    "    dataset = Dataset.from_dict({\"formatted_chat\": dataset})\n",
    "    return dataset.map(lambda x: {\"formatted_chat\": tokenizer.apply_chat_template(x, tokenize=False, add_generation_prompt=False)})\n",
    "\n",
    "def get_translation_loss(examples):\n",
    "    input_ids = tokenizer.apply_chat_template(examples, return_tensors=\"pt\", thinking=False, return_dict=True, add_generation_prompt=True).to(device)\n",
    "    print(input_ids)\n",
    "    \n",
    "\n",
    "with open(\"data/coco.ml.txt\", \"r\") as f:\n",
    "    src_data = f.readlines()\n",
    "\n",
    "with open(\"data/coco.en.txt\", \"r\") as f:\n",
    "    dest_data = f.readlines()\n",
    "\n",
    "data = preprocess_data(src_data[:10], dest_data[:10])\n",
    "data"
   ],
   "id": "1daf0deb54b5bc9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "298c20f7b556466e8e9caaaa59f7510e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UndefinedError",
     "evalue": "datasets.formatting.formatting.LazyRow object has no element 0",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUndefinedError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mdata/coco.en.txt\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m     17\u001B[39m     dest_data = f.readlines()\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m data = \u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m data\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mpreprocess_data\u001B[39m\u001B[34m(sources, destinations)\u001B[39m\n\u001B[32m      4\u001B[39m dataset = [[{\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTranslate to english: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msrc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m} , {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33massistant\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: dest}] \u001B[38;5;28;01mfor\u001B[39;00m src, dest \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sources, destinations)]\n\u001B[32m      5\u001B[39m dataset = Dataset.from_dict({\u001B[33m\"\u001B[39m\u001B[33mformatted_chat\u001B[39m\u001B[33m\"\u001B[39m: dataset})\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mformatted_chat\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply_chat_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenize\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:602\u001B[39m, in \u001B[36mtransmit_tasks.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    600\u001B[39m     \u001B[38;5;28mself\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mself\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    601\u001B[39m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m602\u001B[39m out: Union[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mDatasetDict\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    603\u001B[39m datasets: List[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mlist\u001B[39m(out.values()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[32m    604\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[32m    605\u001B[39m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:567\u001B[39m, in \u001B[36mtransmit_format.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    560\u001B[39m self_format = {\n\u001B[32m    561\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtype\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_type,\n\u001B[32m    562\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mformat_kwargs\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_kwargs,\n\u001B[32m    563\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._format_columns,\n\u001B[32m    564\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33moutput_all_columns\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m._output_all_columns,\n\u001B[32m    565\u001B[39m }\n\u001B[32m    566\u001B[39m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m567\u001B[39m out: Union[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mDatasetDict\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    568\u001B[39m datasets: List[\u001B[33m\"\u001B[39m\u001B[33mDataset\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mlist\u001B[39m(out.values()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[32m    569\u001B[39m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3167\u001B[39m, in \u001B[36mDataset.map\u001B[39m\u001B[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[39m\n\u001B[32m   3161\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   3162\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[32m   3163\u001B[39m         unit=\u001B[33m\"\u001B[39m\u001B[33m examples\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   3164\u001B[39m         total=pbar_total,\n\u001B[32m   3165\u001B[39m         desc=desc \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mMap\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   3166\u001B[39m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[32m-> \u001B[39m\u001B[32m3167\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mDataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mdataset_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3168\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3169\u001B[39m \u001B[43m                \u001B[49m\u001B[43mshards_done\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3528\u001B[39m, in \u001B[36mDataset._map_single\u001B[39m\u001B[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[39m\n\u001B[32m   3526\u001B[39m _time = time.time()\n\u001B[32m   3527\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, example \u001B[38;5;129;01min\u001B[39;00m shard_iterable:\n\u001B[32m-> \u001B[39m\u001B[32m3528\u001B[39m     example = \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m=\u001B[49m\u001B[43moffset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3529\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m update_data:\n\u001B[32m   3530\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m i == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3427\u001B[39m, in \u001B[36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[39m\u001B[34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[39m\n\u001B[32m   3425\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[32m   3426\u001B[39m     additional_args += (rank,)\n\u001B[32m-> \u001B[39m\u001B[32m3427\u001B[39m processed_inputs = \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfn_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43madditional_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3428\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[32m   3429\u001B[39m     processed_inputs = {\n\u001B[32m   3430\u001B[39m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs.data.items() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs.keys_to_format\n\u001B[32m   3431\u001B[39m     }\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mpreprocess_data.<locals>.<lambda>\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m      4\u001B[39m dataset = [[{\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTranslate to english: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msrc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m} , {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33massistant\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: dest}] \u001B[38;5;28;01mfor\u001B[39;00m src, dest \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sources, destinations)]\n\u001B[32m      5\u001B[39m dataset = Dataset.from_dict({\u001B[33m\"\u001B[39m\u001B[33mformatted_chat\u001B[39m\u001B[33m\"\u001B[39m: dataset})\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m dataset.map(\u001B[38;5;28;01mlambda\u001B[39;00m x: {\u001B[33m\"\u001B[39m\u001B[33mformatted_chat\u001B[39m\u001B[33m\"\u001B[39m: \u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply_chat_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenize\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m})\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1867\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.apply_chat_template\u001B[39m\u001B[34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001B[39m\n\u001B[32m   1865\u001B[39m     all_generation_indices.append(generation_indices)\n\u001B[32m   1866\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1867\u001B[39m     rendered_chat = \u001B[43mcompiled_template\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1868\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1869\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtool_schemas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1870\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1871\u001B[39m \u001B[43m        \u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1872\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtemplate_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1873\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1874\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m continue_final_message:\n\u001B[32m   1875\u001B[39m     final_message = chat[-\u001B[32m1\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/jinja2/environment.py:1295\u001B[39m, in \u001B[36mTemplate.render\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.environment.concat(\u001B[38;5;28mself\u001B[39m.root_render_func(ctx))  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m   1294\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1295\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/jinja2/environment.py:942\u001B[39m, in \u001B[36mEnvironment.handle_exception\u001B[39m\u001B[34m(self, source)\u001B[39m\n\u001B[32m    937\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Exception handling helper.  This is used internally to either raise\u001B[39;00m\n\u001B[32m    938\u001B[39m \u001B[33;03mrewritten exceptions or return a rendered traceback for the template.\u001B[39;00m\n\u001B[32m    939\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    940\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdebug\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m rewrite_traceback_stack\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m rewrite_traceback_stack(source=source)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<template>:1\u001B[39m, in \u001B[36mtop-level template code\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/jinja2/sandbox.py:293\u001B[39m, in \u001B[36mSandboxedEnvironment.getitem\u001B[39m\u001B[34m(self, obj, argument)\u001B[39m\n\u001B[32m    291\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Subscribe an object from sandboxed code.\"\"\"\u001B[39;00m\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m[\u001B[49m\u001B[43margument\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mLookupError\u001B[39;00m):\n\u001B[32m    295\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(argument, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[31mUndefinedError\u001B[39m: datasets.formatting.formatting.LazyRow object has no element 0"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T06:59:00.851801Z",
     "start_time": "2025-03-04T06:59:00.364745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.2-2b-instruct\")"
   ],
   "id": "7c923be80083bd08",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T06:52:37.168458Z",
     "start_time": "2025-03-04T06:52:34.339736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count, n = 0, 10000\n",
    "for i in range(n):\n",
    "    sample = src_data[i]\n",
    "    count += tokenizer.decode(tokenizer.encode(sample)) == sample\n",
    "\n",
    "count / n"
   ],
   "id": "4e5b950333f95aff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:54:37.109483Z",
     "start_time": "2025-03-04T17:54:34.916881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset preparation\n",
    "\n",
    "# {\n",
    "#     \"messages\": [\n",
    "#         {\"role\": \"system\", \"content\": \"Translate the Malayalam text to English.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"മലയാളം ടെക്സ്റ്റ്\"},\n",
    "#         {\"role\": \"assistant\", \"content\": \"Malayalam text\"}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "n = len(src_data)\n",
    "dataset = []\n",
    "for mal, eng in zip(src_data[:n], dest_data[:n]):\n",
    "    sample = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Translate the Malayalam text to English.\"},\n",
    "            {\"role\": \"user\", \"content\": mal.strip()},\n",
    "            {\"role\": \"assistant\", \"content\": eng.strip()}\n",
    "        ]\n",
    "    }\n",
    "    dataset.append({\n",
    "        \"input\": mal.strip(),\n",
    "        \"output\": eng.strip()\n",
    "    })\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"data/trans.jsonl\", \"w\") as f:\n",
    "    for sample in dataset:\n",
    "        f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")"
   ],
   "id": "496e1bfae4b06ddb",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T16:37:28.546608Z",
     "start_time": "2025-03-04T16:37:28.219527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.2-2b-instruct\")\n",
    "\n",
    "sample = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Translate Malayalam to English.\"},\n",
    "        {\"role\": \"user\", \"content\": \"മലയാളം ടെക്സ്റ്റ്\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Malayalam text\"}\n",
    "    ]\n",
    "    \n",
    "}\n",
    "\n",
    "print(tokenizer.apply_chat_template(sample[\"messages\"], tokenize=False))"
   ],
   "id": "28ae58c6ae81d45d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_of_role|>system<|end_of_role|>Translate Malayalam to English.<|end_of_text|>\n",
      "<|start_of_role|>user<|end_of_role|>മലയാളം ടെക്സ്റ്റ്<|end_of_text|>\n",
      "<|start_of_role|>assistant<|end_of_role|>Malayalam text<|end_of_text|>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:16:21.230356Z",
     "start_time": "2025-03-04T17:16:21.225035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "element = {'messages': [{'role': 'system', 'content': 'Translate the Malayalam text to English.'}, {'role': 'user', 'content': 'ഒരു വലിയ...യിൻ ഒരു ട്രെയിൻ സ്റ്റേഷനിൽ ഇരിക്കുന്നു.'}, {'role': 'assistant', 'content': 'A large freight train sits in a train station.'}]}\n",
    "\n",
    "delimiter_token = 17594\n",
    "tokens = tokenizer.apply_chat_template(element['messages'], tokenize=True)\n",
    "input_ids = tokens[:tokens.index(delimiter_token) + 2]\n",
    "labels = tokens[tokens.index(delimiter_token) + 2:]\n",
    "tokenizer.decode(input_ids), tokenizer.decode(labels)"
   ],
   "id": "22b64c02e58438d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|start_of_role|>system<|end_of_role|>Translate the Malayalam text to English.<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>ഒരു വലിയ...യിൻ ഒരു ട്രെയിൻ സ്റ്റേഷനിൽ ഇരിക്കുന്നു.<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>',\n",
       " 'A large freight train sits in a train station.<|end_of_text|>\\n')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:15:37.850472Z",
     "start_time": "2025-03-04T17:15:37.847131Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.apply_chat_template(element['messages'], tokenize=False)",
   "id": "c80d743cc12511f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_of_role|>system<|end_of_role|>Translate the Malayalam text to English.<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>ഒരു വലിയ...യിൻ ഒരു ട്രെയിൻ സ്റ്റേഷനിൽ ഇരിക്കുന്നു.<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>A large freight train sits in a train station.<|end_of_text|>\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:07:55.457229Z",
     "start_time": "2025-03-04T17:07:55.453809Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.chat_template",
   "id": "106ad66868027894",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\'] %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"Knowledge Cutoff Date: April 2024.\\nToday\\'s Date: \" + strftime_now(\\'%B %d, %Y\\') + \".\\nYou are Granite, developed by IBM.\" %}\\n    {%- if tools and documents %}\\n        {%- set system_message = system_message + \" You are a helpful AI assistant with access to the following tools. When a tool is required to answer the user\\'s query, respond with <|tool_call|> followed by a JSON list of tools used. If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\\n\\nWrite the response to the user\\'s input by strictly aligning with the facts in the provided documents. If the information needed to answer the question is not available in the documents, inform the user that the question cannot be answered based on the available data.\" %}\\n    {%- elif tools %}\\n        {%- set system_message = system_message + \" You are a helpful AI assistant with access to the following tools. When a tool is required to answer the user\\'s query, respond with <|tool_call|> followed by a JSON list of tools used. If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\" %}\\n    {%- elif documents %}\\n        {%- set system_message = system_message + \" Write the response to the user\\'s input by strictly aligning with the facts in the provided documents. If the information needed to answer the question is not available in the documents, inform the user that the question cannot be answered based on the available data.\" %}\\n    {%- elif thinking %}\\n    {%- set system_message = system_message + \" You are a helpful AI assistant.\\nRespond to every user query in a comprehensive and detailed way. You can write down your thoughts and reasoning process before responding. In the thought process, engage in a comprehensive cycle of analysis, summarization, exploration, reassessment, reflection, backtracing, and iteration to develop well-considered thinking process. In the response section, based on various attempts, explorations, and reflections from the thoughts section, systematically present the final solution that you deem correct. The response should summarize the thought process. Write your thoughts after \\'Here is my thought process:\\' and write your response after \\'Here is my response:\\' for each user query.\" %}\\n    {%- else %}\\n        {%- set system_message = system_message + \" You are a helpful AI assistant.\" %}    \\n    {%- endif %}\\n    {%- if \\'citations\\' in controls and documents %}\\n        {%- set system_message = system_message + \\'\\n\\nIn your response, use the symbols <co> and </co> to indicate when a fact comes from a document in the search result, e.g <co>0</co> for a fact from document 0. Afterwards, list all the citations with their corresponding documents in an ordered list.\\' %}\\n    {%- endif %}\\n    {%- if \\'hallucinations\\' in controls and documents %}\\n        {%- set system_message = system_message + \\'\\n\\nFinally, after the response is written, include a numbered list of sentences from the response that are potentially hallucinated and not based in the documents.\\' %}\\n    {%- endif %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n{{- \\'<|start_of_role|>system<|end_of_role|>\\' + system_message + \\'<|end_of_text|>\\n\\' }}\\n{%- if tools %}\\n    {{- \\'<|start_of_role|>tools<|end_of_role|>\\' }}\\n    {{- tools | tojson(indent=4) }}\\n    {{- \\'<|end_of_text|>\\n\\' }}\\n{%- endif %}\\n{%- if documents %}\\n    {{- \\'<|start_of_role|>documents<|end_of_role|>\\' }}\\n    {%- for document in documents %}\\n        {{- \\'Document \\' + loop.index0 | string + \\'\\n\\' }}\\n        {{- document[\\'text\\'] }}\\n        {%- if not loop.last %}\\n            {{- \\'\\n\\n\\'}}\\n        {%- endif%}\\n    {%- endfor %}\\n    {{- \\'<|end_of_text|>\\n\\' }}\\n{%- endif %}\\n{%- for message in loop_messages %}\\n    {{- \\'<|start_of_role|>\\' + message[\\'role\\'] + \\'<|end_of_role|>\\' + message[\\'content\\'] + \\'<|end_of_text|>\\n\\' }}\\n    {%- if loop.last and add_generation_prompt %}\\n        {{- \\'<|start_of_role|>assistant\\' }}\\n            {%- if controls %}\\n                {{- \\' \\' + controls | tojson()}}\\n            {%- endif %}\\n        {{- \\'<|end_of_role|>\\' }}\\n    {%- endif %}\\n{%- endfor %}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:20:15.648576Z",
     "start_time": "2025-03-04T17:20:15.643560Z"
    }
   },
   "cell_type": "code",
   "source": "model.modules",
   "id": "6c1e8abb9a859dcf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of GraniteForCausalLM(\n",
       "  (model): GraniteModel(\n",
       "    (embed_tokens): Embedding(49155, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x GraniteDecoderLayer(\n",
       "        (self_attn): GraniteSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): GraniteMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): GraniteRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): GraniteRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): GraniteRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): GraniteRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=49155, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:41:53.481580Z",
     "start_time": "2025-03-08T05:41:53.249325Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c6e3bedd5fa299a4",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\npartially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1764\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1763\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1764\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1765\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001B[39m, in \u001B[36mimport_module\u001B[39m\u001B[34m(name, package)\u001B[39m\n\u001B[32m     89\u001B[39m         level += \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1387\u001B[39m, in \u001B[36m_gcd_import\u001B[39m\u001B[34m(name, package, level)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1360\u001B[39m, in \u001B[36m_find_and_load\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1331\u001B[39m, in \u001B[36m_find_and_load_unlocked\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:935\u001B[39m, in \u001B[36m_load_unlocked\u001B[39m\u001B[34m(spec)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:995\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:488\u001B[39m, in \u001B[36m_call_with_frames_removed\u001B[39m\u001B[34m(f, *args, **kwds)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:26\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature_extraction_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PreTrainedFeatureExtractor\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_processing_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseImageProcessor\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mauto\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfiguration_auto\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoConfig\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:21\u001B[39m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_processing_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BatchFeature, ImageProcessingMixin\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_transforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m center_crop, normalize, rescale\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChannelDimension\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/image_transforms.py:22\u001B[39m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     23\u001B[39m     ChannelDimension,\n\u001B[32m     24\u001B[39m     ImageInput,\n\u001B[32m     25\u001B[39m     get_channel_dimension_axis,\n\u001B[32m     26\u001B[39m     get_image_size,\n\u001B[32m     27\u001B[39m     infer_channel_dimension_format,\n\u001B[32m     28\u001B[39m )\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/image_utils.py:58\u001B[39m\n\u001B[32m     57\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torchvision_available():\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InterpolationMode\n\u001B[32m     60\u001B[39m     pil_torch_interpolation_mapping = {\n\u001B[32m     61\u001B[39m         PILImageResampling.NEAREST: InterpolationMode.NEAREST,\n\u001B[32m     62\u001B[39m         PILImageResampling.BOX: InterpolationMode.BOX,\n\u001B[32m   (...)\u001B[39m\u001B[32m     66\u001B[39m         PILImageResampling.LANCZOS: InterpolationMode.LANCZOS,\n\u001B[32m     67\u001B[39m     }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/torchvision/__init__.py:10\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mextension\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _HAS_OPS  \u001B[38;5;66;03m# usort:skip\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001B[38;5;66;03m# usort:skip\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/torchvision/_meta_registrations.py:25\u001B[39m\n\u001B[32m     22\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m wrapper\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m \u001B[38;5;129;43m@register_meta\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mroi_align\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43mmeta_roi_align\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrois\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspatial_scale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpooled_height\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpooled_width\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maligned\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrois\u001B[49m\u001B[43m.\u001B[49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrois must have shape as Tensor[K, 5]\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/torchvision/_meta_registrations.py:18\u001B[39m, in \u001B[36mregister_meta.<locals>.wrapper\u001B[39m\u001B[34m(fn)\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(fn):\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtorchvision\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextension\u001B[49m._has_ops():\n\u001B[32m     19\u001B[39m         get_meta_lib().impl(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(torch.ops.torchvision, op_name), overload_name), fn)\n",
      "\u001B[31mAttributeError\u001B[39m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[32m      3\u001B[39m translator = pipeline(\u001B[33m\"\u001B[39m\u001B[33mtranslation\u001B[39m\u001B[33m\"\u001B[39m, model=\u001B[33m\"\u001B[39m\u001B[33mHelsinki-NLP/opus-mt-fr-en\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m translator(\u001B[33m\"\u001B[39m\u001B[33mനിരവധി പാറകൾക്കടുത്തുള്ള ട്രാക്കിൽ ഒരു ട്രെയിൻ\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1412\u001B[39m, in \u001B[36m_handle_fromlist\u001B[39m\u001B[34m(module, fromlist, import_, recursive)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1754\u001B[39m, in \u001B[36m_LazyModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1752\u001B[39m     value = Placeholder\n\u001B[32m   1753\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._class_to_module.keys():\n\u001B[32m-> \u001B[39m\u001B[32m1754\u001B[39m     module = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1755\u001B[39m     value = \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[32m   1756\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Workspace/Research/fms-hf-tuning/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1766\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1764\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib.import_module(\u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m + module_name, \u001B[38;5;28mself\u001B[39m.\u001B[34m__name__\u001B[39m)\n\u001B[32m   1765\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m1766\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1767\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m because of the following error (look up to see its\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1768\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1769\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\npartially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T05:51:46.812439Z",
     "start_time": "2025-03-08T05:51:43.762977Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "555e20fd55b77dbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==1.0.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.0.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs==2.4.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.4.4)\r\n",
      "Requirement already satisfied: aiohttp==3.11.11 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (3.11.11)\r\n",
      "Requirement already satisfied: aiosignal==1.3.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.3.2)\r\n",
      "Requirement already satisfied: anyio==4.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.8.0)\r\n",
      "Requirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.1.4)\r\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (23.1.0)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (21.2.0)\r\n",
      "Requirement already satisfied: arrow==1.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (1.3.0)\r\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (3.0.0)\r\n",
      "Requirement already satisfied: async-lru==2.0.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (2.0.4)\r\n",
      "Requirement already satisfied: attrs==25.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (25.1.0)\r\n",
      "Requirement already satisfied: babel==2.17.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (2.17.0)\r\n",
      "Requirement already satisfied: beautifulsoup4==4.13.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (4.13.3)\r\n",
      "Requirement already satisfied: bleach==6.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (6.2.0)\r\n",
      "Requirement already satisfied: boto3==1.37.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (1.37.4)\r\n",
      "Requirement already satisfied: botocore==1.37.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (1.37.4)\r\n",
      "Requirement already satisfied: certifi==2024.12.14 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (2024.12.14)\r\n",
      "Requirement already satisfied: cffi==1.17.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (1.17.1)\r\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (3.4.1)\r\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.2.2)\r\n",
      "Requirement already satisfied: datasets==2.21.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (2.21.0)\r\n",
      "Requirement already satisfied: debugpy==1.8.12 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (1.8.12)\r\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (5.2.1)\r\n",
      "Requirement already satisfied: defusedxml==0.7.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (0.7.1)\r\n",
      "Requirement already satisfied: dill==0.3.8 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (0.3.8)\r\n",
      "Requirement already satisfied: docstring_parser==0.16 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (0.16)\r\n",
      "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (2.2.0)\r\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (2.21.1)\r\n",
      "Requirement already satisfied: filelock==3.17.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (3.17.0)\r\n",
      "Requirement already satisfied: fqdn==1.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (1.5.1)\r\n",
      "Requirement already satisfied: frozenlist==1.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (1.5.0)\r\n",
      "Requirement already satisfied: fsspec==2024.6.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (2024.6.1)\r\n",
      "Requirement already satisfied: h11==0.14.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.14.0)\r\n",
      "Requirement already satisfied: httpcore==1.0.7 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (1.0.7)\r\n",
      "Requirement already satisfied: httpx==0.28.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (0.28.1)\r\n",
      "Requirement already satisfied: huggingface-hub==0.28.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (0.28.1)\r\n",
      "Requirement already satisfied: idna==3.10 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (3.10)\r\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (6.29.5)\r\n",
      "Requirement already satisfied: ipython==9.0.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (9.0.1)\r\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (1.1.1)\r\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (8.1.5)\r\n",
      "Requirement already satisfied: isoduration==20.11.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (20.11.0)\r\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (0.19.2)\r\n",
      "Requirement already satisfied: Jinja2==3.1.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (3.1.5)\r\n",
      "Requirement already satisfied: jmespath==1.0.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (1.0.1)\r\n",
      "Requirement already satisfied: joblib==1.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (1.4.2)\r\n",
      "Requirement already satisfied: json5==0.10.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (0.10.0)\r\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (3.0.0)\r\n",
      "Requirement already satisfied: jsonschema==4.23.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (4.23.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications==2024.10.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (2024.10.1)\r\n",
      "Requirement already satisfied: jupyter==1.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (1.1.1)\r\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (6.6.3)\r\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (0.12.0)\r\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (2.2.5)\r\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (8.6.3)\r\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (5.7.2)\r\n",
      "Requirement already satisfied: jupyter_server==2.15.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (2.15.0)\r\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (0.5.3)\r\n",
      "Requirement already satisfied: jupyterlab==4.3.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (4.3.5)\r\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (0.3.0)\r\n",
      "Requirement already satisfied: jupyterlab_server==2.27.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (2.27.3)\r\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.13 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (3.0.13)\r\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (3.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (3.0.2)\r\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (0.1.7)\r\n",
      "Requirement already satisfied: mdurl==0.1.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (0.1.2)\r\n",
      "Requirement already satisfied: mistune==3.1.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (3.1.2)\r\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (1.3.0)\r\n",
      "Requirement already satisfied: multidict==6.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (6.1.0)\r\n",
      "Requirement already satisfied: multiprocess==0.70.16 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (0.70.16)\r\n",
      "Requirement already satisfied: nbclient==0.10.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (0.10.2)\r\n",
      "Requirement already satisfied: nbconvert==7.16.6 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (7.16.6)\r\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (5.10.4)\r\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (1.6.0)\r\n",
      "Requirement already satisfied: networkx==3.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (3.4.2)\r\n",
      "Requirement already satisfied: ninja==1.11.1.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (1.11.1.3)\r\n",
      "Requirement already satisfied: notebook==7.3.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (7.3.2)\r\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 79)) (0.2.4)\r\n",
      "Requirement already satisfied: numpy==1.26.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 80)) (1.26.4)\r\n",
      "Requirement already satisfied: overrides==7.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 81)) (7.7.0)\r\n",
      "Requirement already satisfied: packaging==24.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 82)) (24.2)\r\n",
      "Requirement already satisfied: pandas==2.2.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 83)) (2.2.3)\r\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 84)) (1.5.1)\r\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 85)) (0.8.4)\r\n",
      "Requirement already satisfied: peft==0.13.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 86)) (0.13.2)\r\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 87)) (4.9.0)\r\n",
      "Requirement already satisfied: pillow==11.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 88)) (11.1.0)\r\n",
      "Requirement already satisfied: platformdirs==4.3.6 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 89)) (4.3.6)\r\n",
      "Requirement already satisfied: prometheus_client==0.21.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 90)) (0.21.1)\r\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 91)) (3.0.50)\r\n",
      "Requirement already satisfied: propcache==0.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 92)) (0.2.1)\r\n",
      "Requirement already satisfied: protobuf==5.29.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 93)) (5.29.3)\r\n",
      "Requirement already satisfied: psutil==6.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 94)) (6.1.1)\r\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 95)) (0.7.0)\r\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 96)) (0.2.3)\r\n",
      "Requirement already satisfied: pyarrow==19.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 97)) (19.0.0)\r\n",
      "Requirement already satisfied: pycparser==2.22 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 98)) (2.22)\r\n",
      "Requirement already satisfied: Pygments==2.19.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 99)) (2.19.1)\r\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 100)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: python-json-logger==3.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 101)) (3.2.1)\r\n",
      "Requirement already satisfied: pytz==2024.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 102)) (2024.2)\r\n",
      "Requirement already satisfied: PyYAML==6.0.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 103)) (6.0.2)\r\n",
      "Requirement already satisfied: pyzmq==26.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 104)) (26.2.1)\r\n",
      "Requirement already satisfied: referencing==0.36.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 105)) (0.36.2)\r\n",
      "Requirement already satisfied: regex==2024.11.6 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 106)) (2024.11.6)\r\n",
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 107)) (2.32.3)\r\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 108)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 109)) (0.1.1)\r\n",
      "Requirement already satisfied: rich==13.9.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 110)) (13.9.4)\r\n",
      "Requirement already satisfied: rpds-py==0.23.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 111)) (0.23.1)\r\n",
      "Requirement already satisfied: s3transfer==0.11.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 112)) (0.11.3)\r\n",
      "Requirement already satisfied: safetensors==0.5.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 113)) (0.5.2)\r\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 114)) (1.6.1)\r\n",
      "Requirement already satisfied: scipy==1.15.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 115)) (1.15.2)\r\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 116)) (1.8.3)\r\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 117)) (0.2.0)\r\n",
      "Requirement already satisfied: setuptools==75.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 118)) (75.8.0)\r\n",
      "Requirement already satisfied: shtab==1.7.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 119)) (1.7.1)\r\n",
      "Requirement already satisfied: simpleeval==0.9.13 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 120)) (0.9.13)\r\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 121)) (1.17.0)\r\n",
      "Requirement already satisfied: sniffio==1.3.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 122)) (1.3.1)\r\n",
      "Requirement already satisfied: soupsieve==2.6 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 123)) (2.6)\r\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 124)) (0.6.3)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 125)) (1.13.1)\r\n",
      "Requirement already satisfied: terminado==0.18.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 126)) (0.18.1)\r\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 127)) (3.5.0)\r\n",
      "Requirement already satisfied: tinycss2==1.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 128)) (1.4.0)\r\n",
      "Requirement already satisfied: tokenizers==0.20.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 129)) (0.20.3)\r\n",
      "Requirement already satisfied: torch==2.4.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 130)) (2.4.1)\r\n",
      "Requirement already satisfied: torchaudio==2.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 131)) (2.6.0)\r\n",
      "Requirement already satisfied: torchvision==0.21.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 132)) (0.21.0)\r\n",
      "Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 133)) (6.4.2)\r\n",
      "Requirement already satisfied: tqdm==4.67.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 134)) (4.67.1)\r\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 135)) (5.14.3)\r\n",
      "Requirement already satisfied: transformers==4.45.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 136)) (4.45.2)\r\n",
      "Requirement already satisfied: trl==0.11.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 137)) (0.11.4)\r\n",
      "Requirement already satisfied: typeguard==4.4.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 138)) (4.4.1)\r\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241206 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 139)) (2.9.0.20241206)\r\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 140)) (4.12.2)\r\n",
      "Requirement already satisfied: tyro==0.9.13 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 141)) (0.9.13)\r\n",
      "Requirement already satisfied: tzdata==2025.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 142)) (2025.1)\r\n",
      "Requirement already satisfied: uri-template==1.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 143)) (1.3.0)\r\n",
      "Requirement already satisfied: urllib3==2.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 144)) (2.3.0)\r\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 145)) (0.2.13)\r\n",
      "Requirement already satisfied: webcolors==24.11.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 146)) (24.11.1)\r\n",
      "Requirement already satisfied: webencodings==0.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 147)) (0.5.1)\r\n",
      "Requirement already satisfied: websocket-client==1.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 148)) (1.8.0)\r\n",
      "Requirement already satisfied: wheel==0.45.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 149)) (0.45.1)\r\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 150)) (4.0.13)\r\n",
      "Requirement already satisfied: xxhash==3.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 151)) (3.5.0)\r\n",
      "Requirement already satisfied: yarl==1.18.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 152)) (1.18.3)\r\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting peft==0.13.2 (from -r requirements.txt (line 86))\r\n",
      "  Obtaining dependency information for peft==0.13.2 from https://files.pythonhosted.org/packages/78/9d/5f95bfb298c8d3b4e3a107701f9a4e7774a0d4d1f8eb0c9d5420b80f7c9d/peft-0.13.2-py3-none-any.whl.metadata\r\n",
      "  Using cached peft-0.13.2-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting accelerate==1.0.1 (from -r requirements.txt (line 1))\r\n",
      "  Obtaining dependency information for accelerate==1.0.1 from https://files.pythonhosted.org/packages/2c/92/48aec3736ca778ffe5fa68e19e3c18917cba4de43fa46fe6176cccafe267/accelerate-1.0.1-py3-none-any.whl.metadata\r\n",
      "  Using cached accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\r\n",
      "\u001B[31mERROR: Cannot install -r requirements.txt (line 1), -r requirements.txt (line 86), torch==2.4.1 and torchaudio==2.6.0 because these package versions have conflicting dependencies.\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "The conflict is caused by:\r\n",
      "    The user requested torch==2.4.1\r\n",
      "    accelerate 1.0.1 depends on torch>=1.10.0\r\n",
      "    peft 0.13.2 depends on torch>=1.13.0\r\n",
      "    torchaudio 2.6.0 depends on torch==2.6.0\r\n",
      "\r\n",
      "To fix this you could try to:\r\n",
      "1. loosen the range of package versions you've specified\r\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\r\n",
      "\r\n",
      "\u001B[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
